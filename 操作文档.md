# CI-SDR 系统操作文档

本文档提供详细的操作步骤，指导您从零开始使用CI-SDR系统进行情感偏差消除推荐系统的训练和评估。

## 目录

1. [环境准备](#环境准备)
2. [数据准备](#数据准备)
3. [模型训练](#模型训练)
4. [模型评估](#模型评估)
5. [参数调优](#参数调优)
6. [常见问题](#常见问题)
7. [完整示例](#完整示例)

---

## 环境准备

### 步骤1：检查Python版本

确保您的Python版本 >= 3.8：

```bash
python --version
# 或
python3 --version
```

如果版本低于3.8，请先升级Python。

### 步骤2：创建虚拟环境（推荐）

```bash
# 创建虚拟环境
python -m venv venv

# 激活虚拟环境
# macOS/Linux:
source venv/bin/activate
# Windows:
# venv\Scripts\activate
```

### 步骤3：安装依赖包

```bash
# 确保在项目根目录
cd /Users/qing/PycharmProjects/sentiment_basis

# 安装所有依赖
pip install -r requirements.txt
```

### 步骤4：验证安装

```bash
# 验证PyTorch安装
python -c "import torch; print(f'PyTorch版本: {torch.__version__}')"

# 验证其他关键包
python -c "import pandas; import numpy; import gensim; print('所有依赖包安装成功！')"
```

---

## 数据准备

### 方式1：使用示例数据（快速测试）

```bash
# 生成示例数据集
python generate_sample_data.py

# 这将在 data/ 目录下生成 sample_reviews.json 文件
# 默认生成5000条样本数据
```

### 方式2：准备真实数据集

#### 数据格式要求

您的数据文件可以是JSON或CSV格式，必须包含以下字段：

**JSON格式示例：**
```json
[
  {
    "user_id": "A1XX2XX3XX4XX5",
    "item_id": "B0001XX2XX",
    "rating": 5,
    "review_text": "This is a great product! I highly recommend it to everyone."
  },
  {
    "user_id": "A1XX2XX3XX4XX5",
    "item_id": "B0002XX3XX",
    "rating": 3,
    "review_text": "It's okay, nothing special. Average quality."
  }
]
```

**CSV格式示例：**
```csv
user_id,item_id,rating,review_text
A1XX2XX3XX4XX5,B0001XX2XX,5,"This is a great product! I highly recommend it to everyone."
A1XX2XX3XX4XX5,B0002XX3XX,3,"It's okay, nothing special. Average quality."
```

#### 数据要求

- **user_id**: 用户唯一标识符（字符串或整数）
- **item_id**: 物品唯一标识符（字符串或整数）
- **rating**: 评分值（1-5之间的整数或浮点数）
- **review_text**: 评论文本（字符串，不能为空）

#### 数据预处理建议

1. **数据清洗**：
   - 移除评论文本为空的记录
   - 移除评分不在1-5范围内的记录
   - 移除重复记录

2. **数据量要求**：
   - 建议至少5000条记录以确保Word2Vec模型训练效果
   - 每个用户至少1条记录
   - 每个物品至少1条记录

3. **保存数据**：
   将处理好的数据保存到 `data/` 目录下，例如：
   ```bash
   # 示例
   data/amazon_gourmet.json
   data/yelp_reviews.json
   ```

---

## 模型训练

### 基础训练命令

```bash
python train.py --data_path data/sample_reviews.json --epochs 50
```

### 完整参数说明

```bash
python train.py \
    --data_path data/sample_reviews.json \    # 数据文件路径（必需）
    --epochs 50 \                              # 训练轮数（默认：50）
    --batch_size 256 \                         # 批次大小（默认：256）
    --lr 0.002 \                               # 学习率（默认：0.002）
    --weight_decay 1e-6 \                      # 权重衰减（默认：1e-6）
    --alpha_u 0.001 \                          # 用户情感分支权重（默认：0.001）
    --alpha_i 0.001 \                          # 物品情感分支权重（默认：0.001）
    --save_dir checkpoints                     # 模型保存目录（默认：checkpoints）
```

### 训练过程说明

训练过程会显示以下信息：

1. **数据加载阶段**：
   ```
   加载数据集...
   正在训练Word2Vec模型...
   Word2Vec模型训练完成
   正在生成评论嵌入向量...
   嵌入向量生成完成
   ```

2. **模型初始化**：
   ```
   初始化模型...
   模型参数数量: [参数总数]
   ```

3. **训练循环**：
   ```
   Epoch 1/50
   Training - 总计: 2.3456, L_RC: 2.1234, L_U: 1.8765, L_I: 1.9234
   验证指标 - MSE: 1.8567, BU: 0.3456, BI: 0.2789
   保存最佳模型 (MSE: 1.8567)
   ```

### 训练输出

训练完成后，您会在 `checkpoints/` 目录下找到：
- `best_model.pth`: 最佳模型文件（验证集上MSE最低的模型）

### 训练时间估算

- **小数据集**（5000条记录）：约10-30分钟
- **中等数据集**（50,000条记录）：约1-2小时
- **大数据集**（500,000+条记录）：约数小时

*注：训练时间取决于数据量、硬件配置（CPU/GPU）等因素*

---

## 模型评估

### 基础评估命令

```bash
python evaluate.py --model_path checkpoints/best_model.pth --beta 0.1
```

### 完整参数说明

```bash
python evaluate.py \
    --model_path checkpoints/best_model.pth \  # 模型文件路径（必需）
    --data_path data/sample_reviews.json \     # 测试数据路径（默认：使用训练数据）
    --beta 0.1 \                                # 去偏参数（默认：0.1，范围：[1e-5, 0.5]）
    --batch_size 256 \                          # 批次大小（默认：256）
    --use_debiased                              # 使用去偏推理（默认：True）
```

### 评估输出说明

评估完成后会显示：

```
评估结果:
MSE: 1.8567
BU (User Sentiment Bias): 0.2345
BI (Item Sentiment Bias): 0.1876

结果已保存到: checkpoints/best_model_results.json
```

**指标解释**：
- **MSE（均方误差）**：越小越好，表示整体预测准确度
- **BU（用户情感偏差）**：越小越好，表示对积极用户和消极用户的推荐公平性
- **BI（物品情感偏差）**：越小越好，表示对热门物品和冷门物品的推荐公平性

### 结果文件

评估结果会保存为JSON文件，例如：`checkpoints/best_model_results.json`

```json
{
  "model_path": "checkpoints/best_model.pth",
  "beta": 0.1,
  "use_debiased": true,
  "metrics": {
    "MSE": 1.8567,
    "BU": 0.2345,
    "BI": 0.1876
  }
}
```

---

## 参数调优

### beta参数调优

`beta` 参数控制去偏强度，需要通过实验找到最佳值。

#### 调优步骤

1. **设置beta候选值**：
   ```bash
   # 在config.py中设置，或通过命令行参数
   betas = [0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5]
   ```

2. **批量评估**：
   ```bash
   for beta in 0.01 0.05 0.1 0.2 0.3 0.4 0.5; do
       echo "评估 beta=$beta"
       python evaluate.py --model_path checkpoints/best_model.pth --beta $beta
   done
   ```

3. **选择最佳beta**：
   - 平衡MSE、BU和BI三个指标
   - 优先考虑BU和BI较低的值
   - 在BU和BI相近的情况下，选择MSE较低的值

#### beta参数影响

| beta值 | 去偏效果 | 预测性能 | 适用场景 |
|--------|---------|---------|---------|
| 很小（<0.01） | 弱 | 较好 | 预测性能优先 |
| 中等（0.1-0.2） | 中等 | 平衡 | **推荐** |
| 较大（>0.3） | 强 | 可能下降 | 去偏优先 |

### 其他超参数调整

#### 1. 学习率（lr）

```bash
# 如果损失不收敛，尝试降低学习率
python train.py --data_path data/sample_reviews.json --lr 0.001

# 如果训练太慢，可以适当提高学习率
python train.py --data_path data/sample_reviews.json --lr 0.003
```

#### 2. 批次大小（batch_size）

```bash
# 内存不足时减小批次大小
python train.py --data_path data/sample_reviews.json --batch_size 128

# 内存充足时可以增大批次大小以加速训练
python train.py --data_path data/sample_reviews.json --batch_size 512
```

#### 3. 情感分支权重（alpha_u, alpha_i）

```bash
# 增强情感分支的影响
python train.py --data_path data/sample_reviews.json --alpha_u 0.01 --alpha_i 0.01

# 减弱情感分支的影响
python train.py --data_path data/sample_reviews.json --alpha_u 0.0001 --alpha_i 0.0001
```

---

## 常见问题

### 问题1：内存不足（Out of Memory）

**症状**：
```
RuntimeError: CUDA out of memory
```

**解决方案**：
1. 减小批次大小：
   ```bash
   python train.py --data_path data/your_data.json --batch_size 64
   ```
2. 如果使用GPU，可以减少GPU内存使用：
   ```python
   # 在config.py中
   DEVICE = torch.device("cpu")  # 使用CPU
   ```

### 问题2：Word2Vec训练失败

**症状**：
```
KeyError: 'word'
```

**解决方案**：
1. 检查数据中是否有足够的评论文本
2. 确保评论文本不为空
3. 增大最小词频阈值（在`utils/embeddings.py`中修改`min_count`参数）

### 问题3：模型收敛慢或不收敛

**解决方案**：
1. 降低学习率：
   ```bash
   python train.py --data_path data/your_data.json --lr 0.0005
   ```
2. 检查数据质量，确保评分分布合理
3. 增加训练轮数：
   ```bash
   python train.py --data_path data/your_data.json --epochs 100
   ```

### 问题4：BU或BI指标异常高

**解决方案**：
1. 调整beta参数，尝试更大的值
2. 检查数据中用户和物品的情感分布是否均匀
3. 确保训练数据量足够大

### 问题5：导入错误

**症状**：
```
ModuleNotFoundError: No module named 'xxx'
```

**解决方案**：
```bash
# 重新安装依赖
pip install -r requirements.txt --upgrade
```

### 问题6：数据格式错误

**症状**：
```
KeyError: 'user_id'
```

**解决方案**：
1. 检查数据文件是否包含必需字段：`user_id`, `item_id`, `rating`, `review_text`
2. 检查字段名称是否正确（区分大小写）
3. 检查JSON格式是否正确（使用JSON验证工具）

---

## 完整示例

### 示例1：从零开始完整流程

```bash
# 1. 环境准备
cd /Users/qing/PycharmProjects/sentiment_basis
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt

# 2. 生成示例数据
python generate_sample_data.py

# 3. 训练模型（50个epoch）
python train.py --data_path data/sample_reviews.json --epochs 50

# 4. 评估模型（使用默认beta=0.1）
python evaluate.py --model_path checkpoints/best_model.pth --beta 0.1

# 5. 尝试不同的beta值
python evaluate.py --model_path checkpoints/best_model.pth --beta 0.05
python evaluate.py --model_path checkpoints/best_model.pth --beta 0.2
```

### 示例2：使用真实数据集

```bash
# 假设您已经准备好Amazon数据集
# 文件路径：data/amazon_gourmet.json

# 1. 训练模型
python train.py \
    --data_path data/amazon_gourmet.json \
    --epochs 100 \
    --batch_size 512 \
    --lr 0.002

# 2. beta参数搜索
for beta in 0.01 0.05 0.1 0.15 0.2; do
    echo "========== beta = $beta =========="
    python evaluate.py \
        --model_path checkpoints/best_model.pth \
        --data_path data/amazon_gourmet_test.json \
        --beta $beta
done

# 3. 根据结果选择最佳beta值，再次评估
python evaluate.py \
    --model_path checkpoints/best_model.pth \
    --data_path data/amazon_gourmet_test.json \
    --beta 0.1  # 假设0.1是最佳值
```

### 示例3：对比去偏前后的效果

```bash
# 评估不去偏的效果
python evaluate.py \
    --model_path checkpoints/best_model.pth \
    --beta 0.0 \
    --use_debiased

# 评估去偏后的效果
python evaluate.py \
    --model_path checkpoints/best_model.pth \
    --beta 0.1 \
    --use_debiased

# 对比MSE、BU、BI指标的变化
```

### 示例4：自定义配置训练

```bash
# 创建自定义配置文件或修改config.py
# 然后使用默认参数训练
python train.py --data_path data/your_data.json

# 或者使用命令行参数覆盖配置
python train.py \
    --data_path data/your_data.json \
    --epochs 80 \
    --batch_size 128 \
    --lr 0.001 \
    --alpha_u 0.005 \
    --alpha_i 0.005
```

---

## 最佳实践建议

1. **数据准备**
   - 确保数据质量：清理异常值、处理缺失值
   - 数据量建议：至少5000条记录
   - 数据平衡：尽量保证用户和物品的分布相对均匀

2. **训练过程**
   - 从较小的epoch数开始（如20-30），观察损失下降趋势
   - 如果损失下降缓慢，可以适当增加epoch数
   - 关注验证集上的MSE、BU、BI指标，选择综合表现最好的模型

3. **参数调优**
   - beta参数是影响去偏效果的关键，建议进行网格搜索
   - 从0.1开始，在[0.01, 0.5]范围内尝试5-10个值
   - 平衡MSE、BU、BI三个指标，不要只追求单一指标

4. **模型评估**
   - 使用独立的测试集进行评估（不要在训练集上评估）
   - 多次运行取平均值，减少随机性影响
   - 记录不同beta值下的指标，便于分析和对比

5. **结果分析**
   - BU和BI越小越好，说明模型对不同类型用户和物品的推荐更公平
   - 如果BU和BI仍然较高，可以尝试：
     - 增大beta值
     - 调整alpha_u和alpha_i参数
     - 增加训练数据量
     - 调整模型架构参数

---

## 联系与支持

如遇到问题，请检查：
1. 本文档的"常见问题"部分
2. `README.md` 和 `USAGE.md` 文档
3. `IMPLEMENTATION.md` 了解实现细节

祝您使用愉快！

